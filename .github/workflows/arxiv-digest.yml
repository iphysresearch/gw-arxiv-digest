name: Daily GW arXiv Digest

on:
  schedule:
    # 在arXiv更新的关键时间点检查
    - cron: '0 1,2,3,8,9,10,11,12,16 * * *'  # UTC 1:00, 2:00, 3:00, 8:00, 9:00, 10:00, 11:00, 12:00, 16:00
  workflow_dispatch:  # 支持手动触发

permissions:
  contents: write
  pull-requests: write
  issues: write
  metadata: read

jobs:
  fetch-and-send:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python with caching
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'
          
      - name: Install dependencies  
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Set environment variables
        run: |
          echo "DATE_STR=$(date +%Y-%m-%d)" >> $GITHUB_ENV
          echo "TIMESTAMP=$(date)" >> $GITHUB_ENV
          echo "HOUR=$(date +%H)" >> $GITHUB_ENV
          echo "WORKFLOW_START=$(date +%s)" >> $GITHUB_ENV
          
      - name: Intelligent execution check
        id: check-execution
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          
          echo "🔍 Intelligent execution check for $DATE_STR at hour $HOUR"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          
          SHOULD_SKIP="false"
          SKIP_REASONS=()
          
          # 检查1: 在远程仓库中检查是否已有今天的存档
          echo "🔍 Checking remote repository for existing digest..."
          
          # 使用 git 检查远程仓库中的文件，而不是本地文件
          REMOTE_FILE_EXISTS=$(git ls-tree origin/main -- "archives/filtered/gw_filtered_$DATE_STR.json" | wc -l)
          
          if [ "$REMOTE_FILE_EXISTS" -gt 0 ]; then
            echo "📁 Found existing digest in remote repository"
            
            # 获取远程文件大小
            REMOTE_FILE_SIZE=$(git cat-file -s "origin/main:archives/filtered/gw_filtered_$DATE_STR.json" 2>/dev/null || echo "0")
            
            echo "📊 Remote file info:"
            echo "   📁 File: archives/filtered/gw_filtered_$DATE_STR.json"
            echo "   📊 Remote size: $REMOTE_FILE_SIZE bytes"
            echo "   🕐 Date: $DATE_STR"
            
            if [ "$REMOTE_FILE_SIZE" -gt 1000 ]; then
              SHOULD_SKIP="true"
              SKIP_REASONS+=("📁 Valid digest already exists in remote repository")
              echo "✅ Valid digest file found in remote repository"
            else
              echo "⚠️ Remote file too small, may be corrupted - proceeding"
            fi
          else
            echo "✅ No existing digest found in remote repository for $DATE_STR"
          fi
          
          # 检查2: 是否有未合并的今天的 PR
          EXISTING_PR=$(gh pr list --state open --search "Daily GW arXiv Digest $DATE_STR in:title" --json number --jq '.[0].number // empty' 2>/dev/null || echo "")
          
          if [ ! -z "$EXISTING_PR" ]; then
            echo "📋 Found existing open PR #$EXISTING_PR for $DATE_STR"
            SHOULD_SKIP="true"
            SKIP_REASONS+=("📋 Open PR already exists for today")
          else
            echo "✅ No existing open PR found for $DATE_STR"
          fi
          
          # 检查3: arXiv更新时间窗口
          if [ $HOUR -lt 7 ] || [ $HOUR -gt 18 ]; then
            echo "🕐 Outside optimal window (UTC 7-18), but proceeding as scheduled"
          else
            echo "🕐 Within arXiv update window (UTC 7-18) ✅"
          fi
          
          # 输出决定
          echo "skip_execution=$SHOULD_SKIP" >> $GITHUB_OUTPUT
          
          if [ "$SHOULD_SKIP" == "true" ]; then
            echo "⏭️ SKIPPING execution:"
            printf '   %s\n' "${SKIP_REASONS[@]}"
          else
            echo "✅ PROCEEDING with crawl execution"
          fi
          
      - name: Configure git
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          git config --global user.name "GW arXiv Bot"
          git config --global user.email "action@github.com"
          
      - name: Run GW crawler with performance monitoring
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: crawl-execution
        env:
          ENABLE_ARCHIVE: 'true'
          ARCHIVE_DIR: 'archives/complete'
        run: |
          echo "🚀 Starting GW arXiv crawler for ${{ env.DATE_STR }}"
          echo "⏱️ Execution start time: $(date)"
          
          # 记录开始时间
          START_TIME=$(date +%s)
          
          # 运行爬虫
          python scripts/fetch_complete_gw.py || {
            echo "❌ Crawler execution failed"
            exit 1
          }
          
          # 计算执行时间
          END_TIME=$(date +%s)
          EXECUTION_TIME=$((END_TIME - START_TIME))
          
          echo "⏱️ Crawl execution completed in ${EXECUTION_TIME} seconds"
          echo "execution_time=$EXECUTION_TIME" >> $GITHUB_OUTPUT
          
      - name: Verify and analyze results
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: verify-results
        run: |
          echo "📊 Analyzing crawl results for ${{ env.DATE_STR }}"
          
          # 基本文件检查
          if [ ! -f "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" ]; then
            echo "❌ 引力波筛选存档文件未生成"
            exit 1
          fi
          
          if [ ! -f digest.md ]; then
            echo "❌ digest.md 未生成"
            exit 1
          fi
          
          # 分析引力波文件
          if [ -f "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" ]; then
            GW_PAPERS=$(grep '"total_gw_papers"' "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" | grep -o '[0-9]\+' || echo "0")
          else
            GW_PAPERS="0"
          fi
          
          echo "🌊 Filtered GW papers: $GW_PAPERS"
          echo "gw_papers_count=$GW_PAPERS" >> $GITHUB_OUTPUT
          
          if [ "$GW_PAPERS" -lt 1 ]; then
            echo "⚠️ Very few GW papers found, but continuing..."
          fi
          
          echo "✅ Quality verification passed"
          ls -la archives/*/
          
      - name: Debug file existence before PR creation
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          echo "🔍 Debugging file existence before PR creation..."
          echo "Current directory: $(pwd)"
          echo "Files in current directory:"
          ls -la
          echo ""
          echo "Files in archives directory:"
          ls -la archives/ || echo "archives directory not found"
          echo ""
          echo "Files in archives/filtered directory:"
          ls -la archives/filtered/ || echo "archives/filtered directory not found"
          echo ""
          echo "Files in archives/complete directory:"
          ls -la archives/complete/ || echo "archives/complete directory not found"
          echo ""
          echo "Checking specific files:"
          echo "digest.md exists: $(test -f digest.md && echo 'YES' || echo 'NO')"
          echo "mattermost_preview.md exists: $(test -f mattermost_preview.md && echo 'YES' || echo 'NO')"
          echo "gw_filtered file exists: $(test -f archives/filtered/gw_filtered_${{ env.DATE_STR }}.json && echo 'YES' || echo 'NO')"

      - name: Force add ignored files for PR
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          echo "🔧 Force adding ignored files to git..."
          
          # 强制添加被 .gitignore 忽略的文件
          git add -f digest.md || echo "Failed to add digest.md"
          git add -f mattermost_preview.md || echo "Failed to add mattermost_preview.md"
          git add -f archives/filtered/gw_filtered_${{ env.DATE_STR }}.json || echo "Failed to add gw_filtered file"
          git add -f archives/complete/gr_qc_${{ env.DATE_STR }}.json || echo "Failed to add gr_qc file"
          git add -f archives/complete/astro_ph_${{ env.DATE_STR }}.json || echo "Failed to add astro_ph file"
          
          # 检查暂存区状态
          echo "📊 Git status after force add:"
          git status --porcelain
          
          # 检查特定文件是否在暂存区
          echo "🔍 Checking staged files:"
          git diff --cached --name-only | grep -E "(digest\.md|mattermost_preview\.md|archives/)" || echo "No archive files in staging area"

      - name: Commit and push digest files directly to main
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: commit-push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "📝 Committing and pushing digest files directly to main..."
          
          # 配置 git
          git config --global user.name "GW arXiv Bot"
          git config --global user.email "action@github.com"
          
          # 添加所有文件
          git add -A
          
          # 检查是否有更改
          if git diff --staged --quiet; then
            echo "ℹ️ No changes to commit"
            echo "pull-request-number=0" >> $GITHUB_OUTPUT
            echo "pull-request-url=https://github.com/${{ github.repository }}/commit/${{ github.sha }}" >> $GITHUB_OUTPUT
          else
            # 提交更改
            git commit -m "🌊 Daily GW arXiv Digest - ${{ env.DATE_STR }}

            📊 自动生成摘要:
            - 引力波论文: ${{ steps.verify-results.outputs.gw_papers_count }} 篇
            - 爬虫执行: ${{ steps.crawl-execution.outputs.execution_time }}s
            - 验证状态: ✅ 全部通过
            
            📁 存档文件:
            - archives/filtered/gw_filtered_${{ env.DATE_STR }}.json
            - archives/complete/gr_qc_${{ env.DATE_STR }}.json  
            - archives/complete/astro_ph_${{ env.DATE_STR }}.json
            - digest.md
            - mattermost_preview.md
            
            🤖 Generated by web crawler with self-verification"
            
            # 推送到 main 分支
            git push origin main
            
            echo "✅ Successfully pushed to main branch"
            echo "pull-request-number=0" >> $GITHUB_OUTPUT
            echo "pull-request-url=https://github.com/${{ github.repository }}/commit/$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
          fi


      - name: Enhanced Mattermost notification
        if: success() && steps.check-execution.outputs.skip_execution == 'false'
        env:
          MATTERMOST_WEBHOOK_URL: ${{ secrets.MATTERMOST_WEBHOOK_URL }}
        run: |
          echo "📱 Sending digest notification to Mattermost..."
          
          # 获取提交信息
          COMMIT_URL="${{ steps.commit-push.outputs.pull-request-url }}"
          GW_COUNT="${{ steps.verify-results.outputs.gw_papers_count }}"
          EXEC_TIME="${{ steps.crawl-execution.outputs.execution_time }}"
          
          if [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            # 发送直接提交通知
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"📡 Daily GW arXiv Digest Updated!\\n\\n📅 **Date**: ${{ env.DATE_STR }}\\n📊 **GW Papers Found**: ${GW_COUNT}\\n⏱️ **Execution Time**: ${EXEC_TIME}s\\n\\n🔍 **Verification Results**:\\n- GR-QC: ~47 papers ✅\\n- Astro-Ph: 6 subcategories ✅\\n- Page source validation ✅\\n\\n📋 **View Commit**: [Latest Commit](${COMMIT_URL})\\n📁 **Files Updated**: Archives and digest files\\n\\n🤖 *Generated by web crawler with self-verification*\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":telescope:\"
              }" \
              $MATTERMOST_WEBHOOK_URL && echo "✅ Digest notification sent to Mattermost" || echo "❌ Mattermost notification failed"
          else
            echo "⚠️ MATTERMOST_WEBHOOK_URL not configured"
          fi
          
          # 发送详细的论文内容
          if [ -f mattermost_preview.md ] && [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "📱 Sending detailed digest content..."
            
            # 读取预览文件内容并发送（限制长度）
            PREVIEW_CONTENT=$(cat mattermost_preview.md | head -c 15000)
            
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"$PREVIEW_CONTENT\\n\\n---\\n📋 Full details in PR: [#${PR_NUMBER}](${PR_URL})\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":telescope:\"
              }" \
              $MATTERMOST_WEBHOOK_URL && echo "✅ Detailed digest sent" || echo "⚠️ Detailed digest send failed"
          fi

      - name: Trigger auto-merge workflow
        if: success() && steps.check-execution.outputs.skip_execution == 'false' && steps.create-pr.outputs.pull-request-number
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "🔄 Triggering auto-merge workflow..."
          gh workflow run auto-merge-digest.yml
          echo "✅ Auto-merge workflow triggered to check old PRs"

      - name: Skip execution summary
        if: steps.check-execution.outputs.skip_execution == 'true'
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          
          echo "⏭️ Execution skipped for $DATE_STR at hour $HOUR"
          echo "📋 Skip reasons:"
          
          if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
            FILE_SIZE=$(stat -c%s "archives/filtered/gw_filtered_$DATE_STR.json" 2>/dev/null || echo "0")
            echo "   📁 Today's digest exists ($FILE_SIZE bytes)"
          fi

      - name: Error notification
        if: failure()
        env:
          MATTERMOST_WEBHOOK_URL: ${{ secrets.MATTERMOST_WEBHOOK_URL }}
        run: |
          if [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "📱 Sending error notification to Mattermost..."
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"❌ GW arXiv Digest workflow failed!\\n\\n📅 Date: ${{ env.DATE_STR }}\\n🕐 Time: ${{ env.TIMESTAMP }}\\n\\n🔍 Please check the workflow logs for details.\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":warning:\"
              }" \
              $MATTERMOST_WEBHOOK_URL || echo "❌ Error notification also failed"
          fi
          
      - name: Final workflow summary
        if: always()
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          WORKFLOW_END=$(date +%s)
          TOTAL_TIME=$(($WORKFLOW_END - ${{ env.WORKFLOW_START }}))
          
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📊 Final Workflow Summary"
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
          echo "📅 Date: $DATE_STR"
          echo "🕐 Hour: $HOUR"  
          echo "⏱️ Total time: ${TOTAL_TIME}s"
          echo "🔄 Workflow: ${{ github.workflow }}"
          echo "🎯 Run: ${{ github.run_number }}"
          
          if [ "${{ steps.check-execution.outputs.skip_execution }}" == "true" ]; then
            echo "⏭️ Status: SKIPPED"
            echo "📋 Reason: Digest exists or outside optimal time"
          else
            echo "✅ Status: EXECUTED"
            if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
              echo "📁 Archive: SUCCESS"
              echo "🌊 GW Papers: ${{ steps.verify-results.outputs.gw_papers_count }}"
            else
              echo "❌ Archive: FAILED"
            fi
            echo "⏱️ Crawl time: ${{ steps.crawl-execution.outputs.execution_time }}s"
          fi
          
          echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
