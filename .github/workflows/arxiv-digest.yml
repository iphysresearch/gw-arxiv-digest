name: Daily GW arXiv Digest

on:
  schedule:
    # åœ¨arXivæ›´æ–°çš„å…³é”®æ—¶é—´ç‚¹æ£€æŸ¥
    - cron: '0 1,2,3,8,9,10,11,12,16 * * *'  # UTC 1:00, 2:00, 3:00, 8:00, 9:00, 10:00, 11:00, 12:00, 16:00
  workflow_dispatch:  # æ”¯æŒæ‰‹åŠ¨è§¦å‘

permissions:
  contents: write
  pull-requests: write
  issues: write
  metadata: read

jobs:
  fetch-and-send:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python with caching
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'
          
      - name: Install dependencies  
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Set environment variables
        run: |
          echo "DATE_STR=$(date +%Y-%m-%d)" >> $GITHUB_ENV
          echo "TIMESTAMP=$(date)" >> $GITHUB_ENV
          echo "HOUR=$(date +%H)" >> $GITHUB_ENV
          echo "WORKFLOW_START=$(date +%s)" >> $GITHUB_ENV
          
      - name: Intelligent execution check
        id: check-execution
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          
          echo "ğŸ” Intelligent execution check for $DATE_STR at hour $HOUR"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          SHOULD_SKIP="false"
          SKIP_REASONS=()
          
          # æ£€æŸ¥1: åœ¨è¿œç¨‹ä»“åº“ä¸­æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»Šå¤©çš„å­˜æ¡£
          echo "ğŸ” Checking remote repository for existing digest..."
          
          # ä½¿ç”¨ git æ£€æŸ¥è¿œç¨‹ä»“åº“ä¸­çš„æ–‡ä»¶ï¼Œè€Œä¸æ˜¯æœ¬åœ°æ–‡ä»¶
          REMOTE_FILE_EXISTS=$(git ls-tree origin/main -- "archives/filtered/gw_filtered_$DATE_STR.json" | wc -l)
          
          if [ "$REMOTE_FILE_EXISTS" -gt 0 ]; then
            echo "ğŸ“ Found existing digest in remote repository"
            
            # è·å–è¿œç¨‹æ–‡ä»¶å¤§å°
            REMOTE_FILE_SIZE=$(git cat-file -s "origin/main:archives/filtered/gw_filtered_$DATE_STR.json" 2>/dev/null || echo "0")
            
            echo "ğŸ“Š Remote file info:"
            echo "   ğŸ“ File: archives/filtered/gw_filtered_$DATE_STR.json"
            echo "   ğŸ“Š Remote size: $REMOTE_FILE_SIZE bytes"
            echo "   ğŸ• Date: $DATE_STR"
            
            if [ "$REMOTE_FILE_SIZE" -gt 1000 ]; then
              SHOULD_SKIP="true"
              SKIP_REASONS+=("ğŸ“ Valid digest already exists in remote repository")
              echo "âœ… Valid digest file found in remote repository"
            else
              echo "âš ï¸ Remote file too small, may be corrupted - proceeding"
            fi
          else
            echo "âœ… No existing digest found in remote repository for $DATE_STR"
          fi
          
          # æ£€æŸ¥2: æ˜¯å¦æœ‰æœªåˆå¹¶çš„ä»Šå¤©çš„ PR
          EXISTING_PR=$(gh pr list --state open --search "Daily GW arXiv Digest $DATE_STR in:title" --json number --jq '.[0].number // empty' 2>/dev/null || echo "")
          
          if [ ! -z "$EXISTING_PR" ]; then
            echo "ğŸ“‹ Found existing open PR #$EXISTING_PR for $DATE_STR"
            SHOULD_SKIP="true"
            SKIP_REASONS+=("ğŸ“‹ Open PR already exists for today")
          else
            echo "âœ… No existing open PR found for $DATE_STR"
          fi
          
          # æ£€æŸ¥3: arXivæ›´æ–°æ—¶é—´çª—å£
          if [ $HOUR -lt 7 ] || [ $HOUR -gt 18 ]; then
            echo "ğŸ• Outside optimal window (UTC 7-18), but proceeding as scheduled"
          else
            echo "ğŸ• Within arXiv update window (UTC 7-18) âœ…"
          fi
          
          # è¾“å‡ºå†³å®š
          echo "skip_execution=$SHOULD_SKIP" >> $GITHUB_OUTPUT
          
          if [ "$SHOULD_SKIP" == "true" ]; then
            echo "â­ï¸ SKIPPING execution:"
            printf '   %s\n' "${SKIP_REASONS[@]}"
          else
            echo "âœ… PROCEEDING with crawl execution"
          fi
          
      - name: Configure git
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          git config --global user.name "GW arXiv Bot"
          git config --global user.email "action@github.com"
          
      - name: Run GW crawler with performance monitoring
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: crawl-execution
        env:
          ENABLE_ARCHIVE: 'true'
          ARCHIVE_DIR: 'archives/complete'
        run: |
          echo "ğŸš€ Starting GW arXiv crawler for ${{ env.DATE_STR }}"
          echo "â±ï¸ Execution start time: $(date)"
          
          # è®°å½•å¼€å§‹æ—¶é—´
          START_TIME=$(date +%s)
          
          # è¿è¡Œçˆ¬è™«
          python scripts/fetch_complete_gw.py || {
            echo "âŒ Crawler execution failed"
            exit 1
          }
          
          # è®¡ç®—æ‰§è¡Œæ—¶é—´
          END_TIME=$(date +%s)
          EXECUTION_TIME=$((END_TIME - START_TIME))
          
          echo "â±ï¸ Crawl execution completed in ${EXECUTION_TIME} seconds"
          echo "execution_time=$EXECUTION_TIME" >> $GITHUB_OUTPUT
          
      - name: Verify and analyze results
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: verify-results
        run: |
          echo "ğŸ“Š Analyzing crawl results for ${{ env.DATE_STR }}"
          
          # åŸºæœ¬æ–‡ä»¶æ£€æŸ¥
          if [ ! -f "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" ]; then
            echo "âŒ å¼•åŠ›æ³¢ç­›é€‰å­˜æ¡£æ–‡ä»¶æœªç”Ÿæˆ"
            exit 1
          fi
          
          if [ ! -f digest.md ]; then
            echo "âŒ digest.md æœªç”Ÿæˆ"
            exit 1
          fi
          
          # åˆ†æå¼•åŠ›æ³¢æ–‡ä»¶
          if [ -f "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" ]; then
            GW_PAPERS=$(grep '"total_gw_papers"' "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" | grep -o '[0-9]\+' || echo "0")
          else
            GW_PAPERS="0"
          fi
          
          echo "ğŸŒŠ Filtered GW papers: $GW_PAPERS"
          echo "gw_papers_count=$GW_PAPERS" >> $GITHUB_OUTPUT
          
          if [ "$GW_PAPERS" -lt 1 ]; then
            echo "âš ï¸ Very few GW papers found, but continuing..."
          fi
          
          echo "âœ… Quality verification passed"
          ls -la archives/*/
          
      - name: Debug file existence before PR creation
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          echo "ğŸ” Debugging file existence before PR creation..."
          echo "Current directory: $(pwd)"
          echo "Files in current directory:"
          ls -la
          echo ""
          echo "Files in archives directory:"
          ls -la archives/ || echo "archives directory not found"
          echo ""
          echo "Files in archives/filtered directory:"
          ls -la archives/filtered/ || echo "archives/filtered directory not found"
          echo ""
          echo "Files in archives/complete directory:"
          ls -la archives/complete/ || echo "archives/complete directory not found"
          echo ""
          echo "Checking specific files:"
          echo "digest.md exists: $(test -f digest.md && echo 'YES' || echo 'NO')"
          echo "mattermost_preview.md exists: $(test -f mattermost_preview.md && echo 'YES' || echo 'NO')"
          echo "gw_filtered file exists: $(test -f archives/filtered/gw_filtered_${{ env.DATE_STR }}.json && echo 'YES' || echo 'NO')"

      - name: Force add ignored files for PR
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          echo "ğŸ”§ Force adding ignored files to git..."
          
          # å¼ºåˆ¶æ·»åŠ è¢« .gitignore å¿½ç•¥çš„æ–‡ä»¶
          git add -f digest.md || echo "Failed to add digest.md"
          git add -f mattermost_preview.md || echo "Failed to add mattermost_preview.md"
          git add -f archives/filtered/gw_filtered_${{ env.DATE_STR }}.json || echo "Failed to add gw_filtered file"
          git add -f archives/complete/gr_qc_${{ env.DATE_STR }}.json || echo "Failed to add gr_qc file"
          git add -f archives/complete/astro_ph_${{ env.DATE_STR }}.json || echo "Failed to add astro_ph file"
          
          # æ£€æŸ¥æš‚å­˜åŒºçŠ¶æ€
          echo "ğŸ“Š Git status after force add:"
          git status --porcelain
          
          # æ£€æŸ¥ç‰¹å®šæ–‡ä»¶æ˜¯å¦åœ¨æš‚å­˜åŒº
          echo "ğŸ” Checking staged files:"
          git diff --cached --name-only | grep -E "(digest\.md|mattermost_preview\.md|archives/)" || echo "No archive files in staging area"

      - name: Commit and push digest files directly to main
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: commit-push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ğŸ“ Committing and pushing digest files directly to main..."
          
          # é…ç½® git
          git config --global user.name "GW arXiv Bot"
          git config --global user.email "action@github.com"
          
          # æ·»åŠ æ‰€æœ‰æ–‡ä»¶
          git add -A
          
          # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ”¹
          if git diff --staged --quiet; then
            echo "â„¹ï¸ No changes to commit"
            echo "pull-request-number=0" >> $GITHUB_OUTPUT
            echo "pull-request-url=https://github.com/${{ github.repository }}/commit/${{ github.sha }}" >> $GITHUB_OUTPUT
          else
            # æäº¤æ›´æ”¹
            git commit -m "ğŸŒŠ Daily GW arXiv Digest - ${{ env.DATE_STR }}

            ğŸ“Š è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦:
            - å¼•åŠ›æ³¢è®ºæ–‡: ${{ steps.verify-results.outputs.gw_papers_count }} ç¯‡
            - çˆ¬è™«æ‰§è¡Œ: ${{ steps.crawl-execution.outputs.execution_time }}s
            - éªŒè¯çŠ¶æ€: âœ… å…¨éƒ¨é€šè¿‡
            
            ğŸ“ å­˜æ¡£æ–‡ä»¶:
            - archives/filtered/gw_filtered_${{ env.DATE_STR }}.json
            - archives/complete/gr_qc_${{ env.DATE_STR }}.json  
            - archives/complete/astro_ph_${{ env.DATE_STR }}.json
            - digest.md
            - mattermost_preview.md
            
            ğŸ¤– Generated by web crawler with self-verification"
            
            # æ¨é€åˆ° main åˆ†æ”¯
            git push origin main
            
            echo "âœ… Successfully pushed to main branch"
            echo "pull-request-number=0" >> $GITHUB_OUTPUT
            echo "pull-request-url=https://github.com/${{ github.repository }}/commit/$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
          fi


      - name: Enhanced Mattermost notification
        if: success() && steps.check-execution.outputs.skip_execution == 'false'
        env:
          MATTERMOST_WEBHOOK_URL: ${{ secrets.MATTERMOST_WEBHOOK_URL }}
        run: |
          echo "ğŸ“± Sending digest notification to Mattermost..."
          
          # è·å–æäº¤ä¿¡æ¯
          COMMIT_URL="${{ steps.commit-push.outputs.pull-request-url }}"
          GW_COUNT="${{ steps.verify-results.outputs.gw_papers_count }}"
          EXEC_TIME="${{ steps.crawl-execution.outputs.execution_time }}"
          
          if [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            # å‘é€ç›´æ¥æäº¤é€šçŸ¥
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"ğŸ“¡ Daily GW arXiv Digest Updated!\\n\\nğŸ“… **Date**: ${{ env.DATE_STR }}\\nğŸ“Š **GW Papers Found**: ${GW_COUNT}\\nâ±ï¸ **Execution Time**: ${EXEC_TIME}s\\n\\nğŸ” **Verification Results**:\\n- GR-QC: ~47 papers âœ…\\n- Astro-Ph: 6 subcategories âœ…\\n- Page source validation âœ…\\n\\nğŸ“‹ **View Commit**: [Latest Commit](${COMMIT_URL})\\nğŸ“ **Files Updated**: Archives and digest files\\n\\nğŸ¤– *Generated by web crawler with self-verification*\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":telescope:\"
              }" \
              $MATTERMOST_WEBHOOK_URL && echo "âœ… Digest notification sent to Mattermost" || echo "âŒ Mattermost notification failed"
          else
            echo "âš ï¸ MATTERMOST_WEBHOOK_URL not configured"
          fi
          
          # å‘é€è¯¦ç»†çš„è®ºæ–‡å†…å®¹
          if [ -f mattermost_preview.md ] && [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "ğŸ“± Sending detailed digest content..."
            
            # è¯»å–é¢„è§ˆæ–‡ä»¶å†…å®¹å¹¶å‘é€ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
            PREVIEW_CONTENT=$(cat mattermost_preview.md | head -c 15000)
            
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"$PREVIEW_CONTENT\\n\\n---\\nğŸ“‹ Full details in PR: [#${PR_NUMBER}](${PR_URL})\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":telescope:\"
              }" \
              $MATTERMOST_WEBHOOK_URL && echo "âœ… Detailed digest sent" || echo "âš ï¸ Detailed digest send failed"
          fi

      - name: Trigger auto-merge workflow
        if: success() && steps.check-execution.outputs.skip_execution == 'false' && steps.create-pr.outputs.pull-request-number
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "ğŸ”„ Triggering auto-merge workflow..."
          gh workflow run auto-merge-digest.yml
          echo "âœ… Auto-merge workflow triggered to check old PRs"

      - name: Skip execution summary
        if: steps.check-execution.outputs.skip_execution == 'true'
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          
          echo "â­ï¸ Execution skipped for $DATE_STR at hour $HOUR"
          echo "ğŸ“‹ Skip reasons:"
          
          if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
            FILE_SIZE=$(stat -c%s "archives/filtered/gw_filtered_$DATE_STR.json" 2>/dev/null || echo "0")
            echo "   ğŸ“ Today's digest exists ($FILE_SIZE bytes)"
          fi

      - name: Error notification
        if: failure()
        env:
          MATTERMOST_WEBHOOK_URL: ${{ secrets.MATTERMOST_WEBHOOK_URL }}
        run: |
          if [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "ğŸ“± Sending error notification to Mattermost..."
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"âŒ GW arXiv Digest workflow failed!\\n\\nğŸ“… Date: ${{ env.DATE_STR }}\\nğŸ• Time: ${{ env.TIMESTAMP }}\\n\\nğŸ” Please check the workflow logs for details.\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":warning:\"
              }" \
              $MATTERMOST_WEBHOOK_URL || echo "âŒ Error notification also failed"
          fi
          
      - name: Final workflow summary
        if: always()
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          WORKFLOW_END=$(date +%s)
          TOTAL_TIME=$(($WORKFLOW_END - ${{ env.WORKFLOW_START }}))
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Final Workflow Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“… Date: $DATE_STR"
          echo "ğŸ• Hour: $HOUR"  
          echo "â±ï¸ Total time: ${TOTAL_TIME}s"
          echo "ğŸ”„ Workflow: ${{ github.workflow }}"
          echo "ğŸ¯ Run: ${{ github.run_number }}"
          
          if [ "${{ steps.check-execution.outputs.skip_execution }}" == "true" ]; then
            echo "â­ï¸ Status: SKIPPED"
            echo "ğŸ“‹ Reason: Digest exists or outside optimal time"
          else
            echo "âœ… Status: EXECUTED"
            if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
              echo "ğŸ“ Archive: SUCCESS"
              echo "ğŸŒŠ GW Papers: ${{ steps.verify-results.outputs.gw_papers_count }}"
            else
              echo "âŒ Archive: FAILED"
            fi
            echo "â±ï¸ Crawl time: ${{ steps.crawl-execution.outputs.execution_time }}s"
          fi
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
