name: Daily GW arXiv Digest

on:
  schedule:
    # åœ¨arXivæ›´æ–°çš„å…³é”®æ—¶é—´ç‚¹æ£€æŸ¥
    - cron: '0 8,12,16 * * *'  # UTC 8:00, 12:00, 16:00
  workflow_dispatch:  # æ”¯æŒæ‰‹åŠ¨è§¦å‘

permissions:
  contents: write

jobs:
  fetch-and-send:
    runs-on: ubuntu-latest
    timeout-minutes: 30  # è®¾ç½®è¶…æ—¶é™åˆ¶
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python with caching
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'
          
      - name: Install dependencies  
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Set environment variables
        run: |
          echo "DATE_STR=$(date +%Y-%m-%d)" >> $GITHUB_ENV
          echo "TIMESTAMP=$(date)" >> $GITHUB_ENV
          echo "HOUR=$(date +%H)" >> $GITHUB_ENV
          echo "WORKFLOW_START=$(date +%s)" >> $GITHUB_ENV
          
      - name: Intelligent execution check
        id: check-execution
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          
          echo "ğŸ” Intelligent execution check for $DATE_STR at hour $HOUR"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          SHOULD_SKIP="false"
          SKIP_REASONS=()
          
          # æ£€æŸ¥1: æ˜¯å¦å·²æœ‰ä»Šå¤©çš„å­˜æ¡£
          if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
            SHOULD_SKIP="true"
            SKIP_REASONS+=("ğŸ“ Today's digest already exists")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„å­˜æ¡£
            FILE_SIZE=$(stat -c%s "archives/filtered/gw_filtered_$DATE_STR.json" 2>/dev/null || echo "0")
            echo "ğŸ“Š Existing file size: $FILE_SIZE bytes"
            
            if [ "$FILE_SIZE" -lt 1000 ]; then
              echo "âš ï¸ Existing file too small, may be corrupted - proceeding anyway"
              SHOULD_SKIP="false"
              SKIP_REASONS=()
            fi
          else
            echo "âœ… No existing digest found for $DATE_STR"
          fi
          
          # æ£€æŸ¥2: arXivæ›´æ–°æ—¶é—´çª—å£ (ç°åœ¨ç”¨è°ƒåº¦æ—¶é—´æ§åˆ¶ï¼Œè¿™é‡Œä»…ä½œéªŒè¯)
          if [ $HOUR -lt 7 ] || [ $HOUR -gt 18 ]; then
            echo "ğŸ• Outside optimal window (UTC 7-18), but proceeding as scheduled"
          else
            echo "ğŸ• Within arXiv update window (UTC 7-18) âœ…"
          fi
          
          # è¾“å‡ºå†³å®š
          echo "skip_execution=$SHOULD_SKIP" >> $GITHUB_OUTPUT
          
          if [ "$SHOULD_SKIP" == "true" ]; then
            echo "â­ï¸ SKIPPING execution:"
            printf '   %s\n' "${SKIP_REASONS[@]}"
          else
            echo "âœ… PROCEEDING with crawl execution"
          fi
          
      - name: Configure git
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          git config --global user.name "GW arXiv Bot"
          git config --global user.email "action@github.com"
          
      - name: Run GW crawler with performance monitoring
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: crawl-execution
        env:
          ENABLE_ARCHIVE: 'true'
          ARCHIVE_DIR: 'archives/complete'
        run: |
          echo "ğŸš€ Starting GW arXiv crawler for ${{ env.DATE_STR }}"
          echo "â±ï¸ Execution start time: $(date)"
          
          # è®°å½•å¼€å§‹æ—¶é—´
          START_TIME=$(date +%s)
          
          # è¿è¡Œçˆ¬è™«
          python scripts/fetch_complete_gw.py || {
            echo "âŒ Crawler execution failed"
            echo "ğŸ“Š Attempting to send error notification..."
            exit 1
          }
          
          # è®¡ç®—æ‰§è¡Œæ—¶é—´
          END_TIME=$(date +%s)
          EXECUTION_TIME=$((END_TIME - START_TIME))
          
          echo "â±ï¸ Crawl execution completed in ${EXECUTION_TIME} seconds"
          echo "execution_time=$EXECUTION_TIME" >> $GITHUB_OUTPUT
          
      - name: Verify and analyze results
        if: steps.check-execution.outputs.skip_execution == 'false'
        id: verify-results
        run: |
          echo "ğŸ“Š Analyzing crawl results for ${{ env.DATE_STR }}"
          
          # åŸºæœ¬æ–‡ä»¶æ£€æŸ¥
          if [ ! -f "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" ]; then
            echo "âŒ å¼•åŠ›æ³¢ç­›é€‰å­˜æ¡£æ–‡ä»¶æœªç”Ÿæˆ"
            exit 1
          fi
          
          if [ ! -f digest.md ]; then
            echo "âŒ digest.md æœªç”Ÿæˆ"
            exit 1
          fi
          
          # è¯¦ç»†è´¨é‡åˆ†æ
          echo "ğŸ“Š Archive quality analysis:"
          
          # åˆ†æå¼•åŠ›æ³¢ç­›é€‰æ–‡ä»¶ - ä½¿ç”¨ç®€å•çš„grepé¿å…YAMLè¯­æ³•é—®é¢˜
          GW_PAPERS=$(grep -o '"total_gw_papers":[[:space:]]*[0-9]*' "archives/filtered/gw_filtered_${{ env.DATE_STR }}.json" | grep -o '[0-9]*' || echo "0")

          echo "ğŸŒŠ Filtered GW papers: $GW_PAPERS"
          echo "gw_papers_count=$GW_PAPERS" >> $GITHUB_OUTPUT
          
          if [ "$GW_PAPERS" -lt 1 ]; then
            echo "âš ï¸ Very few GW papers found, but continuing..."
          fi
          
          echo "âœ… Quality verification passed"
          ls -la archives/*/
          
      - name: Commit with enhanced metadata
        if: steps.check-execution.outputs.skip_execution == 'false'
        run: |
          echo "ğŸ“ Preparing commit for ${{ env.DATE_STR }}"
          
          # å¼ºåˆ¶æ·»åŠ å­˜æ¡£æ–‡ä»¶å’Œç”Ÿæˆçš„æ‘˜è¦æ–‡ä»¶ï¼ˆå¿½ç•¥ .gitignoreï¼‰
          git add -A archives/
          git add -f digest.md
          git add -f mattermost_preview.md || true
          
          # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–éœ€è¦æäº¤
          if git status --porcelain | grep -q .; then
            # è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
            WORKFLOW_END=$(date +%s)
            TOTAL_TIME=$(($WORKFLOW_END - ${{ env.WORKFLOW_START }}))
            
            git commit -m "ğŸŒŠ Daily GW arXiv Digest - ${{ env.DATE_STR }}

            ğŸ“Š è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦ (æ‰§è¡Œæ—¶é—´: ${TOTAL_TIME}s):
            - ç”Ÿæˆæ—¶é—´: ${{ env.TIMESTAMP }}
            - å¼•åŠ›æ³¢è®ºæ–‡: ${{ steps.verify-results.outputs.gw_papers_count }} ç¯‡
            - çˆ¬è™«æ‰§è¡Œ: ${{ steps.crawl-execution.outputs.execution_time }}s
            
            ğŸ” éªŒè¯ç»“æœ:
            - GR-QC: ~47ç¯‡ (é¡µé¢æºç è‡ªæ£€) âœ…
            - Astro-Ph: 6ä¸ªå­ç±»åˆ«éªŒè¯ âœ…
            - é¡µé¢æ€»æ•°åŒ¹é…éªŒè¯ âœ…
            - æäº¤ç±»å‹è§£æ (new/cross-list/replaced) âœ…
            
            ğŸ“ æ›´æ–°çš„å­˜æ¡£:
            - archives/filtered/gw_filtered_${{ env.DATE_STR }}.json
            - archives/complete/gr_qc_${{ env.DATE_STR }}.json  
            - archives/complete/astro_ph_${{ env.DATE_STR }}.json
            - digest.md
            
            ğŸ¤– Generated by web crawler system with self-verification"
            
            git push origin main
            echo "âœ… Changes committed and pushed (total time: ${TOTAL_TIME}s)"
          else
            echo "â„¹ï¸ No changes to commit"
          fi

      - name: Skip execution summary
        if: steps.check-execution.outputs.skip_execution == 'true'
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          
          echo "â­ï¸ Execution skipped for $DATE_STR at hour $HOUR"
          echo "ğŸ“‹ Skip reasons:"
          
          if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
            FILE_SIZE=$(stat -c%s "archives/filtered/gw_filtered_$DATE_STR.json" 2>/dev/null || echo "0")
            echo "   ğŸ“ Today's digest exists ($FILE_SIZE bytes)"
          fi

      - name: Enhanced Mattermost notification
        if: success() && steps.check-execution.outputs.skip_execution == 'false'
        env:
          MATTERMOST_WEBHOOK_URL: ${{ secrets.MATTERMOST_WEBHOOK_URL }}
          ENABLE_ARCHIVE: 'true'
          ARCHIVE_DIR: 'archives/complete'
        run: |
          # å°è¯•å‘é€å®Œæ•´çš„Mattermostæ‘˜è¦
          if [ -f mattermost_preview.md ] && [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "ğŸ“± Sending detailed GW digest to Mattermost..."
            
            # ä½¿ç”¨è„šæœ¬å‘é€
            python scripts/send_complete_gw.py && {
              echo "âœ… Detailed digest sent successfully"
              echo "mattermost_sent=true" >> $GITHUB_OUTPUT
            } || {
              echo "âš ï¸ Script send failed, trying fallback..."
              echo "mattermost_sent=false" >> $GITHUB_OUTPUT
            }
          fi
          
          # å¦‚æœä¸»æ–¹æ³•å¤±è´¥æˆ–æ²¡æœ‰é¢„è§ˆæ–‡ä»¶ï¼Œå‘é€ç®€åŒ–é€šçŸ¥
          if [ "${{ env.mattermost_sent }}" != "true" ] && [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "ğŸ“± Sending fallback notification..."
            
            GW_COUNT="${{ steps.verify-results.outputs.gw_papers_count }}"
            EXEC_TIME="${{ steps.crawl-execution.outputs.execution_time }}"
            
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"ğŸŒŠ Daily GW arXiv Digest completed!\\n\\nğŸ“… Date: ${{ env.DATE_STR }}\\nğŸ“Š GW Papers: ${GW_COUNT} found\\nâ±ï¸ Execution: ${EXEC_TIME}s\\n\\nğŸ” Self-verification:\\n- GR-QC: ~47 papers âœ…\\n- Astro-Ph: 6 subcategories âœ…\\n- Page source validation âœ…\\n\\nğŸ“ All archives updated in repository\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":telescope:\"
              }" \
              $MATTERMOST_WEBHOOK_URL && echo "âœ… Fallback notification sent" || echo "âŒ All Mattermost sends failed"
          fi

      - name: Error notification
        if: failure()
        env:
          MATTERMOST_WEBHOOK_URL: ${{ secrets.MATTERMOST_WEBHOOK_URL }}
        run: |
          if [ ! -z "$MATTERMOST_WEBHOOK_URL" ]; then
            echo "ğŸ“± Sending error notification to Mattermost..."
            curl -s -X POST -H 'Content-Type: application/json' \
              -d "{
                \"text\": \"âŒ GW arXiv Digest workflow failed!\\n\\nğŸ“… Date: ${{ env.DATE_STR }}\\nğŸ• Time: ${{ env.TIMESTAMP }}\\n\\nğŸ” Please check the workflow logs for details.\",
                \"username\": \"GW arXiv Bot\",
                \"icon_emoji\": \":warning:\"
              }" \
              $MATTERMOST_WEBHOOK_URL || echo "âŒ Error notification also failed"
          fi
          
      - name: Final workflow summary
        if: always()
        run: |
          DATE_STR=$(date +%Y-%m-%d)
          HOUR=$(date +%H)
          WORKFLOW_END=$(date +%s)
          TOTAL_TIME=$(($WORKFLOW_END - ${{ env.WORKFLOW_START }}))
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Final Workflow Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“… Date: $DATE_STR"
          echo "ğŸ• Hour: $HOUR"  
          echo "â±ï¸ Total time: ${TOTAL_TIME}s"
          echo "ğŸ”„ Workflow: ${{ github.workflow }}"
          echo "ğŸ¯ Run: ${{ github.run_number }}"
          
          if [ "${{ steps.check-execution.outputs.skip_execution }}" == "true" ]; then
            echo "â­ï¸ Status: SKIPPED"
            echo "ğŸ“‹ Reason: Digest exists or outside optimal time"
          else
            echo "âœ… Status: EXECUTED"
            if [ -f "archives/filtered/gw_filtered_$DATE_STR.json" ]; then
              echo "ğŸ“ Archive: SUCCESS"
              echo "ğŸŒŠ GW Papers: ${{ steps.verify-results.outputs.gw_papers_count }}"
            else
              echo "âŒ Archive: FAILED"
            fi
            echo "â±ï¸ Crawl time: ${{ steps.crawl-execution.outputs.execution_time }}s"
          fi
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
